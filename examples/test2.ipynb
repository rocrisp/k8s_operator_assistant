{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://docs.nvidia.com', 'title': 'NVIDIA Documentation Hub - NVIDIA Docs', 'description': 'Get started by exploring the latest technical information and product documentation', 'language': 'en'}, page_content=\"NVIDIA Documentation Hub - NVIDIA DocsSubmit SearchNVIDIA DeveloperBlogForumsJoinSubmit SearchNVIDIA DeveloperBlogForumsJoinMenuNVIDIA Documentation HubGet started by exploring the latest technical information and product documentationBrowse byFeaturedProductsAll DocumentsSubmit SearchMost PopularGet support for our latest innovations and see how you can bring them into your own work.NVIDIA API Documentation        Your guide to NVIDIA APIs including NIM and CUDA-X microservices.                Browse            NVIDIA AI Enterprise        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications.                 Browse            NVIDIA Omniverse        NVIDIA Omniverse is a cloud-native, multi-GPU, real-time simulation and collaboration platform for 3D production pipelines based on Pixar's Universal Scene Description (USD) and NVIDIA RTX.                Browse            NVIDIA CUDA        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications.                Browse            NVIDIA DGX Platform        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution.                 Browse            NVIDIA cuDNN        The NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks.                 Browse            NVIDIA Jetson        The NVIDIA JetPack SDK, which is the most comprehensive solution for building AI applications, along with L4T and L4T Multimedia, provides the Linux kernel, bootloader, NVIDIA drivers, flashing utilities, sample filesystem, and more for the Jetson platform.                Browse            NVIDIA TensorRT        NVIDIA TensorRT is an SDK for high-performance deep learning inference. It is designed to work in a complementary fashion with training frameworks such as TensorFlow, PyTorch, and MXNet. It focuses specifically on running an already-trained network quickly and efficiently on NVIDIA hardware.                Browse            OpenFiltersClose filtersFiltersSelected FiltersClear AllTopics            AR / VR(4)            Computer Vision / Video Analytics(7)            Content Creation / Rendering(9)            Conversational AI(2)            Cybersecurity(2)            Data Center / Cloud(30)            Data Science(9)            Edge Computing(11)            Generative AI / LLMs(2)            Networking(3)            Recommenders / Personalization(3)            Robotics(4)            Simulation / Modeling / Design(11)See AllSee LessIndustry Segments            Academia / Higher Education(37)            Aerospace(42)            Agriculture(38)            Architecture / Engineering / Construction(41)            Automotive / Transportation(9)            Cloud Services(41)            Consumer Internet(37)            Energy(42)            Financial Services(40)            Gaming(48)            Hardware / Semiconductor(40)            Healthcare & Life Sciences(22)            HPC / Scientific Computing(48)            Manufacturing(40)            Media & Entertainment(44)            Public Sector(42)            Restaurant / Quick-Service(39)            Retail / Consumer Packaged Goods(40)            Telecommunications(39)See AllSee LessJob Roles            Artist / Designer(3)            Business Executive(3)            Data Scientist(23)            Dev / IT Operations(38)            Developer / Engineer(60)            Research: Academic(6)            Research: Non-Academic(6)See AllSee LessAPPLYSort by:Alphabetical - A-ZNewestDocumentation CenterCloudera Data Platform (CDP)04/10/23        The integration of NVIDIA RAPIDS into the Cloudera Data Platform (CDP) provides transparent GPU acceleration of data analytics workloads using Apache Spark. This documentation describes the integration and suggested reference architectures for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterFleet Command User Guide06/11/24        NVIDIA Fleet Command brings secure edge AI to enterprises of any size. Transform NVIDIA-certified servers into secure edge appliances and connect them to the cloud in minutes. From the cloud, deploy and manage applications from the NGC Catalog or your NGC Private Registry, update system software over-the-air and manage systems remotely with nothing but a browser and internet connection.    Cloud ServicesEdge ComputingData Center / CloudDocumentation CenterGPU Management and Deployment01/23/23        This documentation should be of interest to cluster admins and support personnel of enterprise GPU deployments. It includes monitoring and management tools and application programming interfaces (APIs), in-field diagnostics and health monitoring, and cluster setup and deployment.    Documentation CenterNVIDIA Megatron-Core03/16/24        Developer documentation for Megatron Core covers API documentation, quickstart guide as well as deep dives into advanced GPU  techniques needed to optimize LLM performance at scale.    Documentation CenternvCOMP01/23/23        nvCOMP is a high performance GPU enabled data compression library. Includes both open-source and non-OS components. The nvCOMP library provides fast lossless data compression and decompression using a GPU. It features generic compression interfaces to enable developers to use high-performance GPU compressors in their applications.    ProductNVIDIA Aerial04/12/23NVIDIA Aerial™ is a suite of accelerated computing platforms, software, and services for designing, simulating, and operating wireless networks. Aerial contains hardened RAN software libraries for telcos, cloud service providers (CSPs), and enterprises building commercial 5G networks. Academic and industry researchers can access Aerial on cloud or on-premises setups for advanced wireless and AI/machine learning (ML) research for 6G.    Edge ComputingTelecommunicationsProductNVIDIA AI Enterprise04/27/23        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications. Easy-to-use microservices provide optimized model performance with enterprise-grade security, support, and stability to ensure a smooth transition from prototype to production for enterprises that run their businesses on AI.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Air06/12/23        A simulation platform that allows users to model data center deployments with full software functionality, creating a digital twin. Transform and streamline network operations by simulating, validating, and automating changes and updates.    Documentation CenterNVIDIA Ansel02/03/23        NVIDIA Ansel is a revolutionary way to capture in-game shots and share the moment. Compose your screenshots from any position, adjust them with post-process filters, capture HDR images in high-fidelity formats, and share them in 360 degrees using your mobile phone, PC, or VR headset.    Documentation CenterNVIDIA API Documentation05/09/24        Your guide to NVIDIA APIs including NIM and CUDA-X microservices.    ProductNVIDIA Base Command Manager10/30/23        NVIDIA Base Command Manager streamlines cluster provisioning, workload management, and infrastructure monitoring. It provides all the tools you need to deploy and manage an AI data center. NVIDIA Base Command Manager Essentials comprises the features of NVIDIA Base Command Manager that are certified for use with NVIDIA AI Enterprise.    Data Center / CloudTechnical OverviewNVIDIA Base Command Platform01/25/23        NVIDIA Base Command Platform is a world-class infrastructure solution for businesses and their data scientists who need a premium AI development experience.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Base OS04/18/23        NVIDIA Base OS implements the stable and fully qualified operating systems for running AI, machine learning, and analytics applications on the DGX platform. It includes system-specific configurations, drivers, and diagnostic and monitoring tools and is available for Ubuntu, Red Hat Enterprise Linux, and Rocky Linux.    Data Center / CloudDocumentation CenterNVIDIA Bright Cluster Manager 03/08/23        NVIDIA Bright Cluster Manager offers fast deployment and end-to-end management for heterogeneous HPC and AI server clusters at the edge, in the data center and in multi/hybrid-cloud environments. It automates provisioning and administration for clusters ranging in size from a single node to hundreds of thousands, supports CPU-based and NVIDIA GPU-accelerated systems, and orchestration with Kubernetes.    HPC / Scientific ComputingEdge ComputingData Center / CloudDocumentation CenterNVIDIA Capture SDK01/23/23        NVIDIA Capture SDK (formerly GRID SDK) enables developers to easily and efficiently capture, and optionally encode, the display content.    Documentation CenterNVIDIA Certification Programs02/06/23        NVIDIA’s program that enables enterprises to confidently deploy hardware solutions that optimally run accelerated workloads—from desktop to data center to edge.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Clara04/27/23        NVIDIA® Clara™ is an open, scalable computing platform that enables developers to build and deploy medical imaging applications into hybrid (embedded, on-premises, or cloud) computing environments to create intelligent instruments and automate healthcare workflows.    Healthcare & Life SciencesComputer Vision / Video AnalyticsProductNVIDIA Cloud Functions        Serverless API to deploy and manage AI workloads on GPUs at planetary scale.    ProductNVIDIA Cloud Native Technologies01/23/23        NVIDIA cloud-native technologies enable developers to build and run GPU-accelerated containers using Docker and Kubernetes.    Cloud ServicesData Center / CloudDocumentation CenterNVIDIA CloudXR SDK02/27/23        CloudXR is NVIDIA's solution for streaming virtual reality (VR), augmented reality (AR), and mixed reality (MR) content from any OpenVR XR application on a remote server--desktop, cloud, data center, or edge.    Documentation CenterNVIDIA Compute Sanitizer04/25/23        Compute Sanitizer is a functional correctness checking suite included in the CUDA toolkit. This suite contains multiple tools that can perform different type of checks. The memcheck tool is capable of precisely detecting and attributing out of bounds and misaligned memory access errors in CUDA applications. The tool can also report hardware exceptions encountered by the GPU. The racecheck tool can report shared memory data access hazards that can cause data races. The initcheck tool can report cases where the GPU performs uninitialized accesses to global memory. The synccheck tool can report cases where the application is attempting invalid usages of synchronization primitives. This document describes the usage of these tools.    ProductNVIDIA CUDA04/03/23        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA cuDNN04/12/23        The NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, attention, matmul, pooling, and normalization.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA cuOpt07/14/23        NVIDIA cuOpt™ is a GPU-accelerated solver that uses heuristics and metaheuristics to solve complex vehicle routing problem variants with a wide range of constraints.    Data ScienceRoboticsProductNVIDIA DALI03/22/23        The NVIDIA Data Loading Library (DALI) is a collection of highly optimized building blocks, and an execution engine, for accelerating the pre-processing of input data for deep learning applications. DALI provides both the performance and the flexibility for accelerating different data pipelines as a single library. This single library can then be easily integrated into different deep learning training and inference applications.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionDocumentation CenterNVIDIA Data Center GPU Drivers01/23/23        NVIDIA Data Center GPU drivers are used in Data Center GPU enterprise deployments for AI, HPC, and accelerated computing workloads. Documentation includes release notes, supported platforms, and cluster setup and deployment.    Documentation CenterNVIDIA Data Center GPU Manager (DCGM)02/03/23        NVIDIA Data Center GPU Manager (DCGM) is a suite of tools for managing and monitoring NVIDIA Data Center GPUs in cluster environments.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionDocumentation CenterNVIDIA Deep Graph Library (DGL)01/23/23        Deep Graph Library (DGL) is a framework-neutral, easy-to-use, and scalable Python library used for implementing and training Graph Neural Networks (GNN). Being framework-neutral, DGL is easily integrated into an existing PyTorch, TensorFlow, or an Apache MXNet workflow.    Documentation CenterNVIDIA Deep Learning Performance07/27/23        GPUs accelerate machine learning operations by performing calculations in parallel. Many operations, especially those representable as matrix multipliers will see good acceleration right out of the box. Even better performance can be achieved by tweaking operation parameters to efficiently use GPU resources. The performance documents present the tips that we think are most widely useful.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA DGX Cloud04/26/24        NVIDIA DGX Cloud is an AI platform for enterprise developers, optimized for the demands of generative AI.    ProductNVIDIA DGX Platform11/03/23        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution. Every aspect of the DGX platform is infused with NVIDIA AI expertise, featuring world-class software, record-breaking NVIDIA-accelerated infrastructure in the cloud or on-premises, and direct access to NVIDIA DGXPerts to speed the ROI of AI for every enterprise.    Hardware / SemiconductorArchitecture / Engineering / ConstructionHPC / Scientific ComputingProductNVIDIA DGX SuperPOD03/17/23        Deployment and management guides for NVIDIA DGX SuperPOD, an AI data center infrastructure platform that enables IT to deliver performance—without compromise—for every user and workload. DGX SuperPOD offers leadership-class accelerated infrastructure and agile, scalable performance for the most challenging AI and high-performance computing (HPC) workloads, with industry-proven results.    Data Center / CloudProductNVIDIA DGX Systems04/24/23        System documentation for the DGX AI supercomputers that deliver world-class performance for large generative AI and mainstream AI workloads.    Data Center / CloudDocumentation CenterNVIDIA DIGITS02/03/23        The NVIDIA Deep Learning GPU Training System (DIGITS) can be used to rapidly train highly accurate deep neural networks (DNNs) for image classification, segmentation, and object-detection tasks. DIGITS simplifies common deep learning tasks such as managing data, designing and training neural networks on multi-GPU systems, monitoring performance in real time with advanced visualizations, and selecting the best-performing model from the results browser for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA DRIVE01/23/23        Learn how to develop for NVIDIA DRIVE®, a scalable computing platform that enables automakers and Tier-1 suppliers to accelerate production of autonomous vehicles.    Documentation CenterNVIDIA EGX01/23/23        The NVIDIA EGX platform delivers the power of accelerated AI computing to the edge with a cloud-native software stack (EGX stack), a range of validated servers and devices, Helm charts, and partners who offer EGX through their products and services.    ProductNVIDIA Enterprise Support and Services06/26/23        NVIDIA’s accelerated computing, visualization, and networking solutions are expediting the speed of business outcomes. NVIDIA’s experts are here for you at every step in this fast-paced journey. With our expansive support tiers, fast implementations, robust professional services, market-leading education, and high caliber technical certifications, we are here to help you achieve success with all parts of NVIDIA’s accelerated computing, visualization, and networking platform.    Documentation CenterNVIDIA FLARE (Federated Learning Active Runtime Environment)02/03/23        FLARE (Federated Learning Active Runtime Environment) is Nvidia’s open source extensible SDK that allows researchers and data scientists to adapt existing ML/DL workflow to a privacy preserving federated paradigm. FLARE makes it possible to build robust, generalizable AI models without sharing data.    ProductNVIDIA Gameworks01/25/23        Documentation for GameWorks-related products and technologies, including libraries (NVAPI, OpenAutomate), code samples (DirectX, OpenGL), and developer tools (Nsight, NVIDIA System Profiler).    GamingContent Creation / RenderingDocumentation CenterNVIDIA GeForce NOW Developer Platform02/03/23        The GeForce NOW Developer Platform is an SDK and toolset empowering integration of, interaction with, and testing on the NVIDIA cloud gaming service.    Documentation CenterNVIDIA GPUDirect Storage06/14/24        NVIDIA GPUDirect Storage (GDS) enables the fastest data path between GPU memory and storage by avoiding copies to and from system memory, thereby increasing storage input/output (IO) bandwidth and decreasing latency and CPU utilization.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA Grace05/30/24        Grace is NVIDIA’s first datacenter CPU. Comprising 72 high-performance Arm v9 cores and featuring the NVIDIA-proprietary Scalable Coherency Fabric (SCF) network-on-chip for incredible core-to-core communication, memory bandwidth and GPU I/O capabilities, Grace provides a high-performance compute foundation in a low-power system-on-chip.    Data Center / CloudDocumentation CenterNVIDIA GVDB Voxels02/03/23        NVIDIA GVDB Voxels is a new framework for simulation, compute and rendering of sparse voxels on the GPU.    Documentation CenterNVIDIA Highlights02/03/23        NVIDIA Highlights enables automatic video capture of key moments, clutch kills, and match-winning plays, ensuring gamers’ best gaming moments are always saved. Once a Highlight is captured, gamers can simply share it directly to Facebook, YouTube, or Weibo right from GeForce Experience’s in-game overlay. Additionally, they can also clip their favorite 15 seconds and share as an animated GIF - all without leaving the game!    ProductNVIDIA Holoscan07/25/23        NVIDIA Holoscan is a hybrid computing platform for medical devices that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core microservices to run surgical video, ultrasound, medical imaging, and other applications anywhere, from embedded to edge to cloud.    Healthcare & Life SciencesDocumentation CenterNVIDIA HPC SDK01/23/23        The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries, and development tools used for developing HPC applications for the NVIDIA platform.    ProductNVIDIA IGX Orin03/23/23        NVIDIA IGX Orin™ is an industrial-grade platform that combines enterprise-level hardware, software, and support. As a single, holistic platform, IGX allows companies to focus on application development and realize the benefits of AI faster.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA IndeX02/03/23        NVIDIA IndeX is a 3D volumetric interactive visualization SDK that allows scientists and researchers to visualize and interact with massive data sets, make real-time modifications, and navigate to the most pertinent parts of the data, all in real-time, to gather better insights faster. IndeX leverages GPU clusters for scalable, real-time, visualization and computing of multi-valued volumetric data together with embedded geometry data.            Load More    OpenFiltersClose filtersFiltersSelected FiltersClear AllProducts            Deep Learning Performance(1)            NVIDIA Air(1)            NVIDIA Virtual GPU (vGPU)(1)Topics            AR / VR(4)            Computer Vision / Video Analytics(7)            Content Creation / Rendering(9)            Conversational AI(2)            Cybersecurity(2)            Data Center / Cloud(30)            Data Science(9)            Edge Computing(11)            Generative AI / LLMs(2)            Networking(3)            Recommenders / Personalization(3)            Robotics(4)            Simulation / Modeling / Design(11)See AllSee LessIndustry Segments            Academia / Higher Education(37)            Aerospace(42)            Agriculture(38)            Architecture / Engineering / Construction(41)            Automotive / Transportation(9)            Cloud Services(41)            Consumer Internet(37)            Energy(42)            Financial Services(40)            Gaming(48)            Hardware / Semiconductor(40)            Healthcare & Life Sciences(22)            HPC / Scientific Computing(48)            Manufacturing(40)            Media & Entertainment(44)            Public Sector(42)            Restaurant / Quick-Service(39)            Retail / Consumer Packaged Goods(40)            Telecommunications(39)See AllSee LessContent Types            Documentation Center(9)            Product(1)            Technical Guide(1)Job Roles            Artist / Designer(3)            Business Executive(3)            Data Scientist(23)            Dev / IT Operations(38)            Developer / Engineer(60)            Research: Academic(6)            Research: Non-Academic(6)See AllSee LessJob Titles            CEO(2)            CTO(5)            Data Analyst(4)            Data Scientist(9)            Developer / Engineer(56)            Film / Video Editor(2)            Graphic Designer / Animator(2)            Industrial Designer / Product Designer(2)            IT Specialist(15)            Solutions Architect(1)            System Administrator(10)See AllSee LessAPPLYProductNVIDIA Virtual GPU (vGPU) Software01/23/23        NVIDIA virtual GPU (vGPU) software is a graphics virtualization platform that extends the power of NVIDIA GPU technology to virtual desktops and apps, offering improved security, productivity, and cost-efficiency.    ProductNVIDIA Clara04/27/23        NVIDIA® Clara™ is an open, scalable computing platform that enables developers to build and deploy medical imaging applications into hybrid (embedded, on-premises, or cloud) computing environments to create intelligent instruments and automate healthcare workflows.    Healthcare & Life SciencesComputer Vision / Video AnalyticsDocumentation CenterNVIDIA Triton Inference Server04/17/23        NVIDIA Triton Inference Server (formerly TensorRT Inference Server) provides a cloud inferencing solution optimized for NVIDIA GPUs. The server provides an inference service via an HTTP or gRPC endpoint, allowing remote clients to request inferencing for any model being managed by the server.    Documentation CenterNVIDIA Maxine02/03/23        NVIDIA Maxine is a GPU-accelerated SDK with state-of-the-art AI features for developers to build virtual collaboration and content creation applications such as video conferencing and live streaming. Maxine’s AI SDKs, such as Video Effects, Audio Effects, and Augmented Reality (AR) are highly optimized and include modular features that can be chained into end-to-end pipelines to deliver the highest performance possible on GPUs, both on PCs and in data centers.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA LaunchPad04/26/23        NVIDIA LaunchPad is a free program that provides users short-term access to a large catalog of hands-on labs. Now enterprises and organizations can immediately tap into the necessary hardware and software stacks to experience end-to-end solution workflows in the areas of AI, data science, 3D design collaboration and simulation, and more.    Edge ComputingData Center / CloudDocumentation CenterNVIDIA GeForce NOW Developer Platform02/03/23        The GeForce NOW Developer Platform is an SDK and toolset empowering integration of, interaction with, and testing on the NVIDIA cloud gaming service.    Documentation CenterNVIDIA VRWorks Graphics02/03/23        VRWorks™ is a comprehensive suite of APIs, libraries, and engines that enable application and headset developers to create amazing virtual reality experiences. VRWorks enables a new level of presence by bringing physically realistic visuals, sound, touch interactions, and simulated environments to virtual reality.    Documentation CenterNVIDIA Data Center GPU Manager (DCGM)02/03/23        NVIDIA Data Center GPU Manager (DCGM) is a suite of tools for managing and monitoring NVIDIA Data Center GPUs in cluster environments.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA Optimized Frameworks        Deep learning (DL) frameworks offer building blocks for designing, training, and validating deep neural networks through a high-level programming interface. Widely-used DL frameworks, such as PyTorch, TensorFlow, PyTorch Geometric, DGL, and others, rely on GPU-accelerated libraries, such as cuDNN, NCCL, and DALI to deliver high-performance, multi-GPU-accelerated training.    Documentation CenterNVIDIA GVDB Voxels02/03/23        NVIDIA GVDB Voxels is a new framework for simulation, compute and rendering of sparse voxels on the GPU.    ProductNVIDIA AI Enterprise04/27/23        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications. Easy-to-use microservices provide optimized model performance with enterprise-grade security, support, and stability to ensure a smooth transition from prototype to production for enterprises that run their businesses on AI.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA MAGNUM IO06/27/23        NVIDIA MAGNUM IO™ software development kit (SDK) enables developers to remove input/output (IO) bottlenecks in AI, high performance computing (HPC), data science, and visualization applications, reducing the end-to-end time of their workflows. Magnum IO covers all aspects of data movement between CPUs, GPUsns, DPUs, and storage subsystems in virtualized, containerized, and bare-metal environments.    ProductNVIDIA CUDA04/03/23        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Trusted Computing Solutions07/25/23        Protecting sensitive and proprietary information using strong hardware-based security.    Healthcare & Life SciencesFinancial ServicesData Center / CloudDocumentation CenterCloudera Data Platform (CDP)04/10/23        The integration of NVIDIA RAPIDS into the Cloudera Data Platform (CDP) provides transparent GPU acceleration of data analytics workloads using Apache Spark. This documentation describes the integration and suggested reference architectures for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Metropolis Microservices for Jetson01/11/24        Metropolis Microservices for Jetson is a platform that simplifies development, deployment and management of Edge AI applications on NVIDIA Jetson. It provides a modular & extensible architecture for developers to distill large complex applications into smaller modular microservice with APIs to integrate into other apps & services.    ProductNVIDIA TAO03/27/23        The NVIDIA TAO Toolkit eliminates the time-consuming process of building and fine-tuning DNNs from scratch for IVA applications.    Public SectorEdge ComputingComputer Vision / Video AnalyticsDocumentation CenterNVIDIA SDK Manager02/03/23        NVIDIA SDK Manager is an all-in-one tool that bundles developer software and provides an end-to-end development environment setup solution for NVIDIA SDKs. Learn about the prerequisite hardware and software to get started with NVIDIA SDK Manager. See the latest features and updates.    Documentation CenterNVIDIA Certification Programs02/06/23        NVIDIA’s program that enables enterprises to confidently deploy hardware solutions that optimally run accelerated workloads—from desktop to data center to edge.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Ansel02/03/23        NVIDIA Ansel is a revolutionary way to capture in-game shots and share the moment. Compose your screenshots from any position, adjust them with post-process filters, capture HDR images in high-fidelity formats, and share them in 360 degrees using your mobile phone, PC, or VR headset.    ProductNVIDIA Holoscan07/25/23        NVIDIA Holoscan is a hybrid computing platform for medical devices that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core microservices to run surgical video, ultrasound, medical imaging, and other applications anywhere, from embedded to edge to cloud.    Healthcare & Life SciencesProductRAPIDS Accelerator for Apache Spark09/14/23        The RAPIDS Accelerator for Apache Spark leverages GPUs to accelerate processing by combining the power of the RAPIDS cuDF library and the scale of the Spark distributed computing framework. You can run your existing Apache Spark applications on GPUs with no code change by launching Spark with the RAPIDS Accelerator for Apache Spark plugin jar and enabling a single configuration setting.    Data ScienceProductNVIDIA License System02/16/23        NVIDIA® License System is used to serve a pool of floating licenses to NVIDIA licensed products. The NVIDIA License System is configured with licenses obtained from the NVIDIA Licensing Portal.    Data Center / CloudProductNVIDIA NIM05/31/24        Part of NVIDIA AI Enterprise, NVIDIA NIM is a set of easy-to-use microservices for accelerating the deployment of foundation models on any cloud or data center and helps keep your data secure. NIM has production-grade runtimes including on-going security updates. Run your business applications with stable APIs backed by enterprise-grade support.    Documentation CenterNVIDIA FLARE (Federated Learning Active Runtime Environment)02/03/23        FLARE (Federated Learning Active Runtime Environment) is Nvidia’s open source extensible SDK that allows researchers and data scientists to adapt existing ML/DL workflow to a privacy preserving federated paradigm. FLARE makes it possible to build robust, generalizable AI models without sharing data.    ProductNVIDIA Base OS04/18/23        NVIDIA Base OS implements the stable and fully qualified operating systems for running AI, machine learning, and analytics applications on the DGX platform. It includes system-specific configurations, drivers, and diagnostic and monitoring tools and is available for Ubuntu, Red Hat Enterprise Linux, and Rocky Linux.    Data Center / CloudTechnical OverviewNVIDIA Base Command Platform01/25/23        NVIDIA Base Command Platform is a world-class infrastructure solution for businesses and their data scientists who need a premium AI development experience.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA NVTAGS03/22/23        NVIDIA Topology-Aware GPU Selection (NVTAGS) intelligently and automatically assigns GPUs to MPI processes, which reduces overall GPU-to-GPU communication time for Message Passing Interface (MPI) applications.    HPC / Scientific ComputingData Center / CloudDocumentation CenterNVIDIA Rivermax02/03/23        Unique IP-based solution that boosts video and data streaming performance. Rivermax together with NVIDIA GPU accelerated computing technologies unlocks innovation for a wide range of applications in Media and Entertainment (M&E), Broadcast, Healthcare, Smart Cities and more.    Documentation CenterNVIDIA Virtual Reality Capture and Replay (VCR) SDK01/23/23        The NVIDIA Virtual Reality Capture and Replay (VCR) SDK enables developers and users to accurately capture and replay VR sessions for performance testing, scene troubleshooting, and more.    Documentation CenterNVIDIA TensorRT-Cloud06/02/24        The Triton Inference Server provides an optimized cloud and edge inferencing solution.    ProductNVIDIA DGX Systems04/24/23        System documentation for the DGX AI supercomputers that deliver world-class performance for large generative AI and mainstream AI workloads.    Data Center / CloudDocumentation CenterNVIDIA Capture SDK01/23/23        NVIDIA Capture SDK (formerly GRID SDK) enables developers to easily and efficiently capture, and optionally encode, the display content.    Documentation CenternvCOMP01/23/23        nvCOMP is a high performance GPU enabled data compression library. Includes both open-source and non-OS components. The nvCOMP library provides fast lossless data compression and decompression using a GPU. It features generic compression interfaces to enable developers to use high-performance GPU compressors in their applications.    ProductNVIDIA DGX Platform11/03/23        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution. Every aspect of the DGX platform is infused with NVIDIA AI expertise, featuring world-class software, record-breaking NVIDIA-accelerated infrastructure in the cloud or on-premises, and direct access to NVIDIA DGXPerts to speed the ROI of AI for every enterprise.    Hardware / SemiconductorArchitecture / Engineering / ConstructionHPC / Scientific ComputingProductNVIDIA Aerial04/12/23NVIDIA Aerial™ is a suite of accelerated computing platforms, software, and services for designing, simulating, and operating wireless networks. Aerial contains hardened RAN software libraries for telcos, cloud service providers (CSPs), and enterprises building commercial 5G networks. Academic and industry researchers can access Aerial on cloud or on-premises setups for advanced wireless and AI/machine learning (ML) research for 6G.    Edge ComputingTelecommunicationsProductNVIDIA Cloud Functions        Serverless API to deploy and manage AI workloads on GPUs at planetary scale.    Documentation CenterNVIDIA PyTorch01/23/23        NVIDIA works with Facebook and the community to accelerate PyTorch on NVIDIA GPUs in the main PyTorch branch, as well as, with ready-to-run containers in NGC.    ProductNVIDIA NVSHMEM08/28/23        NVIDIA NVSHMEM is an NVIDIA based “shared memory” library that provides an easy-to-use CPU-side interface to allocate pinned memory that is symmetrically distributed across a cluster of NVIDIA GPUs.    Data Center / CloudProductNVIDIA Modulus04/28/23        NVIDIA Modulus is a deep learning framework that blends the power of physics and partial differential equations (PDEs) with AI to build more robust models for better analysis.    HPC / Scientific ComputingSimulation / Modeling / DesignDocumentation CenterNVIDIA Bright Cluster Manager 03/08/23        NVIDIA Bright Cluster Manager offers fast deployment and end-to-end management for heterogeneous HPC and AI server clusters at the edge, in the data center and in multi/hybrid-cloud environments. It automates provisioning and administration for clusters ranging in size from a single node to hundreds of thousands, supports CPU-based and NVIDIA GPU-accelerated systems, and orchestration with Kubernetes.    HPC / Scientific ComputingEdge ComputingData Center / CloudProductNVIDIA Networking09/05/23        Accelerated Networks for Modern Workloads: One-third of the 30 million data center servers shipped each year are consumed running the software-defined data center stack.    NetworkingProductNVIDIA MONAI04/19/23        The NVIDIA MONAI framework is the open-source foundation being created by Project MONAI. MONAI is a freely available, community-supported, PyTorch-based framework for deep learning in healthcare imaging. It provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.    Healthcare & Life SciencesComputer Vision / Video AnalyticsProductNVIDIA NGX02/14/23        NVIDIA NGX makes it easy to integrate pre-built, AI-based features into applications with the NGX SDK, NGX Core Runtime and NGX Update Module. The NGX infrastructure updates the AI-based features on all clients that use it.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA DRIVE01/23/23        Learn how to develop for NVIDIA DRIVE®, a scalable computing platform that enables automakers and Tier-1 suppliers to accelerate production of autonomous vehicles.    Documentation CenterNVIDIA RAPIDS 01/23/23        The RAPIDS data science framework is a collection of libraries for running end-to-end data science pipelines completely on the GPU. The interaction is designed to have a familiar look and feel to working in Python, but utilizes optimized NVIDIA CUDA primitives and high-bandwidth GPU memory under the hood.            Load More    Corporate InfoNVIDIA.com HomeAbout NVIDIA\\u200eNVIDIA DeveloperDeveloper HomeBlogResourcesContact UsDeveloper ProgramPrivacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | ContactCopyright © 2024 NVIDIA Corporation\"),\n",
      " Document(metadata={'source': 'https://docs.nvidia.com/cuda', 'title': 'CUDA Toolkit Documentation 12.5', 'language': 'en'}, page_content='CUDA Toolkit Documentation 12.5Release NotesCUDA Features ArchiveEULAInstallation GuidesQuick Start GuideInstallation Guide WindowsInstallation Guide LinuxProgramming GuidesProgramming GuideBest Practices GuideMaxwell Compatibility GuidePascal Compatibility GuideVolta Compatibility GuideTuring Compatibility GuideNVIDIA Ampere GPU Architecture Compatibility GuideHopper Compatibility GuideAda Compatibility GuideMaxwell Tuning GuidePascal Tuning GuideVolta Tuning GuideTuring Tuning GuideNVIDIA Ampere GPU Architecture Tuning GuideHopper Tuning GuideAda Tuning GuidePTX ISAVideo DecoderPTX InteroperabilityInline PTX AssemblyCUDA API ReferencesCUDA Runtime APICUDA Driver APICUDA Math APIcuBLAScuDLA APINVBLASnvJPEGcuFFTCUBCUDA C++ Standard LibrarycuFile API Reference GuidecuRANDcuSPARSENPPnvJitLinknvFatbinNVRTC (Runtime Compilation)ThrustcuSOLVERPTX Compiler API ReferencesPTX Compiler APIsMiscellaneousCUDA Demo SuiteCUDA on WSLCUDA on EFLOWMulti-Instance GPU (MIG)CUDA CompatibilityCUPTIDebugger APIGPUDirect RDMAGPUDirect StoragevGPUToolsNVCCCUDA-GDBCompute SanitizerNsight Eclipse Plugins Installation GuideNsight Eclipse Plugins EditionNsight SystemsNsight ComputeNsight Visual Studio EditionProfilerCUDA Binary UtilitiesWhite PapersFloating Point and IEEE 754Incomplete-LU and Cholesky Preconditioned Iterative MethodsApplication NotesCUDA for TegraCompiler SDKlibNVVM APIlibdevice User’s GuideNVVM IRlanding »CUDA Toolkit Documentation 12.5 Update 1CUDA Toolkit Archive\\r                  -\\r                 \\r                  Send Feedback\\xa0CUDA Toolkit Documentation 12.5 Update 1\\uf0c1Develop, Optimize and Deploy GPU-Accelerated AppsThe NVIDIA® CUDA® Toolkit provides a development environment for creating high performance GPU-accelerated\\rapplications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated\\rembedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.\\rThe toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime\\rlibrary to deploy your application.Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers\\rcan develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.Release NotesThe Release Notes for the CUDA Toolkit.CUDA Features ArchiveThe list of CUDA features by release.EULAThe CUDA Toolkit End User License Agreement applies to the NVIDIA CUDA Toolkit, the NVIDIA CUDA Samples, the NVIDIA Display Driver, NVIDIA Nsight tools (Visual Studio Edition), and the associated documentation on CUDA APIs, programming model and development tools. If you do not agree with the terms and conditions of the license agreement, then do not download or use the software.Installation Guides\\uf0c1Quick Start GuideThis guide provides the minimal first-steps instructions for installation and verifying CUDA on a standard system.Installation Guide WindowsThis guide discusses how to install and check for correct operation of the CUDA Development Tools on Microsoft Windows systems.Installation Guide LinuxThis guide discusses how to install and check for correct operation of the CUDA Development Tools on GNU/Linux systems.Programming Guides\\uf0c1Programming GuideThis guide provides a detailed discussion of the CUDA programming model and programming interface. It then describes the hardware implementation, and provides guidance on how to achieve maximum performance. The appendices include a list of all CUDA-enabled devices, detailed description of all extensions to the C++ language, listings of supported mathematical functions, C++ features supported in host and device code, details on texture fetching, technical specifications of various devices, and concludes by introducing the low-level driver API.Best Practices GuideThis guide presents established parallelization and optimization techniques and explains coding metaphors and idioms that can greatly simplify programming for CUDA-capable GPU architectures. The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the CUDA Toolkit.Maxwell Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Maxwell Architecture. This document provides guidance to ensure that your software applications are compatible with Maxwell.Pascal Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Pascal Architecture. This document provides guidance to ensure that your software applications are compatible with Pascal.Volta Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Volta Architecture. This document provides guidance to ensure that your software applications are compatible with Volta.Turing Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Turing Architecture. This document provides guidance to ensure that your software applications are compatible with Turing.NVIDIA Ampere GPU Architecture Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Ampere GPU Architecture. This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.Hopper Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs. This document provides guidance to ensure that your software applications are compatible with Hopper architecture.Ada Compatibility GuideThis application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs. This document provides guidance to ensure that your software applications are compatible with Ada architecture.Maxwell Tuning GuideMaxwell is NVIDIA’s 4th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Kepler architecture should typically see speedups on the Maxwell architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features.Pascal Tuning GuidePascal is NVIDIA’s 5th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Maxwell architecture should typically see speedups on the Pascal architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features.Volta Tuning GuideVolta is NVIDIA’s 6th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Volta architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features.Turing Tuning GuideTuring is NVIDIA’s 7th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Turing architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features.NVIDIA Ampere GPU Architecture Tuning GuideNVIDIA Ampere GPU Architecture is NVIDIA’s 8th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the NVIDIA Ampere GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architecture’s features.Hopper Tuning GuideHopper GPU Architecture is NVIDIA’s 9th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the Hopper GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architecture’s features.Ada Tuning GuideThe NVIDIA® Ada GPU architecture is NVIDIA’s latest architecture for CUDA® compute applications. The NVIDIA Ada GPU architecture retains and extends the same CUDA programming model provided by previous NVIDIA GPU architectures such as NVIDIA Ampere and Turing, and applications that follow the best practices for those architectures should typically see speedups on the NVIDIA Ada architecture without any code changes. This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architecture’s features.PTX ISAThis guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture (ISA). PTX exposes the GPU as a data-parallel computing device.Video DecoderNVIDIA Video Decoder (NVCUVID) is deprecated. Instead, use the NVIDIA Video Codec SDK (https://developer.nvidia.com/nvidia-video-codec-sdk).PTX InteroperabilityThis document shows how to write PTX that is ABI-compliant and interoperable with other CUDA code.Inline PTX AssemblyThis document shows how to inline PTX (parallel thread execution) assembly language statements into CUDA code. It describes available assembler statement parameters and constraints, and the document also provides a list of some pitfalls that you may encounter.CUDA API References\\uf0c1CUDA Runtime APIFields in structures might appear in order that is different from the order of declaration.CUDA Driver APIFields in structures might appear in order that is different from the order of declaration.CUDA Math APIThe CUDA math API.cuBLASThe cuBLAS library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the NVIDIA CUDA runtime. It allows the user to access the computational resources of NVIDIA Graphical Processing Unit (GPU), but does not auto-parallelize across multiple GPUs.cuDLA APIThe cuDLA API.NVBLASThe NVBLAS library is a multi-GPUs accelerated drop-in BLAS (Basic Linear Algebra Subprograms) built on top of the NVIDIA cuBLAS Library.nvJPEGThe nvJPEG Library provides high-performance GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications.cuFFTThe cuFFT library user guide.CUBThe user guide for CUB.CUDA C++ Standard LibraryThe API reference for libcu++, the CUDA C++ standard library.cuFile API Reference GuideThe NVIDIA® GPUDirect® Storage cuFile API Reference Guide provides information about the preliminary version of the cuFile API reference guide that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs, which are part of the GDS technology.cuRANDThe cuRAND library user guide.cuSPARSEThe cuSPARSE library user guide.NPPNVIDIA NPP is a library of functions for performing CUDA accelerated processing. The initial set of functionality in the library focuses on imaging and video processing and is widely applicable for developers in these areas. NPP will evolve over time to encompass more of the compute heavy tasks in a variety of problem domains. The NPP library is written to maximize flexibility, while maintaining high performance.nvJitLinkThe user guide for the nvJitLink library.nvFatbinThe user guide for the nvFatbin library.NVRTC (Runtime Compilation)NVRTC is a runtime compilation library for CUDA C++. It accepts CUDA C++ source code in character string form and creates handles that can be used to obtain the PTX. The PTX string generated by NVRTC can be loaded by cuModuleLoadData and cuModuleLoadDataEx, and linked with other modules by cuLinkAddData of the CUDA Driver API. This facility can often provide optimizations and performance not possible in a purely offline static compilation.ThrustThe C++ parallel algorithms library.cuSOLVERThe cuSOLVER library user guide.PTX Compiler API References\\uf0c1PTX Compiler APIsThis guide shows how to compile a PTX program into GPU assembly code using APIs provided by the static PTX Compiler library.Miscellaneous\\uf0c1CUDA Demo SuiteThis document describes the demo applications shipped with the CUDA Demo Suite.CUDA on WSLThis guide is intended to help users get started with using NVIDIA CUDA on Windows Subsystem for Linux (WSL 2). The guide covers installation and running CUDA applications and containers in this environment.Multi-Instance GPU (MIG)This edition of the user guide describes the Multi-Instance GPU feature of the NVIDIA® A100 GPU.CUDA CompatibilityThis document describes CUDA Compatibility, including CUDA Enhanced Compatibility and CUDA Forward Compatible Upgrade.CUPTIThe CUPTI-API. The CUDA Profiling Tools Interface (CUPTI) enables the creation of profiling and tracing tools that target CUDA applications.Debugger APIThe CUDA debugger API.GPUDirect RDMAA technology introduced in Kepler-class GPUs and CUDA 5.0, enabling a direct path for communication between the GPU and a third-party peer device on the PCI Express bus when the devices share the same upstream root complex using standard features of PCI Express. This document introduces the technology and describes the steps necessary to enable a GPUDirect RDMA connection to NVIDIA GPUs within the Linux device driver model.GPUDirect StorageThe documentation for GPUDirect Storage.vGPUvGPUs that support CUDA.Tools\\uf0c1NVCCThis is a reference document for nvcc, the CUDA compiler driver. nvcc accepts a range of conventional compiler options, such as for defining macros and include/library paths, and for steering the compilation process.CUDA-GDBThe NVIDIA tool for debugging CUDA applications running on Linux and QNX, providing developers with a mechanism for debugging CUDA applications running on actual hardware. CUDA-GDB is an extension to the x86-64 port of GDB, the GNU Project debugger.Compute SanitizerThe user guide for Compute Sanitizer.Nsight Eclipse Plugins Installation GuideNsight Eclipse Plugins Installation GuideNsight Eclipse Plugins EditionNsight Eclipse Plugins Edition getting started guideNsight SystemsThe documentation for Nsight Systems.Nsight ComputeThe NVIDIA Nsight Compute is the next-generation interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.Nsight Visual Studio EditionThe documentation for Nsight Visual Studio Edition.ProfilerThis is the guide to the Profiler.CUDA Binary UtilitiesThe application notes for cuobjdump, nvdisasm, and nvprune.White Papers\\uf0c1Floating Point and IEEE 754A number of issues related to floating point accuracy and compliance are a frequent source of confusion on both CPUs and GPUs. The purpose of this white paper is to discuss the most common issues related to NVIDIA GPUs and to supplement the documentation in the CUDA C++ Programming Guide.Incomplete-LU and Cholesky Preconditioned Iterative MethodsIn this white paper we show how to use the cuSPARSE and cuBLAS libraries to achieve a 2x speedup over CPU in the incomplete-LU and Cholesky preconditioned iterative methods. We focus on the Bi-Conjugate Gradient Stabilized and Conjugate Gradient iterative methods, that can be used to solve large sparse nonsymmetric and symmetric positive definite linear systems, respectively. Also, we comment on the parallel sparse triangular solve, which is an essential building block in these algorithms.Application Notes\\uf0c1CUDA for TegraThis application note provides an overview of NVIDIA® Tegra® memory architecture and considerations for porting code from a discrete GPU (dGPU) attached to an x86 system to the Tegra® integrated GPU (iGPU). It also discusses EGL interoperability.Compiler SDK\\uf0c1libNVVM APIThe libNVVM API.libdevice User’s GuideThe libdevice library is an LLVM bitcode library that implements common functions for GPU kernels.NVVM IRNVVM IR is a compiler IR (intermediate representation) based on the LLVM IR. The NVVM IR is designed to represent GPU compute kernels (for example, CUDA kernels). High-level language front-ends, like the CUDA C compiler front-end, can generate NVVM IR.Privacy Policy\\r|\\rManage My Privacy\\r|\\rDo Not Sell or Share My Data\\r|\\rTerms of Service\\r|\\rAccessibility\\r|\\rCorporate Policies\\r|\\rProduct Security\\r|\\rContact© Copyright 2007-2024, NVIDIA Corporation & affiliates. All rights reserved.\\r      Last updated on Jul 1, 2024.\\r      '),\n",
      " Document(metadata={'source': 'https://docs.nvidia.com/deeplearning', 'title': 'NVIDIA Documentation Hub - NVIDIA Docs', 'description': 'Get started by exploring the latest technical information and product documentation', 'language': 'en'}, page_content=\"NVIDIA Documentation Hub - NVIDIA DocsSubmit SearchNVIDIA DeveloperBlogForumsJoinSubmit SearchNVIDIA DeveloperBlogForumsJoinMenuNVIDIA Documentation HubGet started by exploring the latest technical information and product documentationBrowse byFeaturedProductsAll DocumentsSubmit SearchMost PopularGet support for our latest innovations and see how you can bring them into your own work.NVIDIA API Documentation        Your guide to NVIDIA APIs including NIM and CUDA-X microservices.                Browse            NVIDIA AI Enterprise        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications.                 Browse            NVIDIA Omniverse        NVIDIA Omniverse is a cloud-native, multi-GPU, real-time simulation and collaboration platform for 3D production pipelines based on Pixar's Universal Scene Description (USD) and NVIDIA RTX.                Browse            NVIDIA CUDA        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications.                Browse            NVIDIA DGX Platform        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution.                 Browse            NVIDIA cuDNN        The NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks.                 Browse            NVIDIA Jetson        The NVIDIA JetPack SDK, which is the most comprehensive solution for building AI applications, along with L4T and L4T Multimedia, provides the Linux kernel, bootloader, NVIDIA drivers, flashing utilities, sample filesystem, and more for the Jetson platform.                Browse            NVIDIA TensorRT        NVIDIA TensorRT is an SDK for high-performance deep learning inference. It is designed to work in a complementary fashion with training frameworks such as TensorFlow, PyTorch, and MXNet. It focuses specifically on running an already-trained network quickly and efficiently on NVIDIA hardware.                Browse            OpenFiltersClose filtersFiltersSelected FiltersClear AllTopics            AR / VR(4)            Computer Vision / Video Analytics(7)            Content Creation / Rendering(9)            Conversational AI(2)            Cybersecurity(2)            Data Center / Cloud(30)            Data Science(9)            Edge Computing(11)            Generative AI / LLMs(2)            Networking(3)            Recommenders / Personalization(3)            Robotics(4)            Simulation / Modeling / Design(11)See AllSee LessIndustry Segments            Academia / Higher Education(37)            Aerospace(42)            Agriculture(38)            Architecture / Engineering / Construction(41)            Automotive / Transportation(9)            Cloud Services(41)            Consumer Internet(37)            Energy(42)            Financial Services(40)            Gaming(48)            Hardware / Semiconductor(40)            Healthcare & Life Sciences(22)            HPC / Scientific Computing(48)            Manufacturing(40)            Media & Entertainment(44)            Public Sector(42)            Restaurant / Quick-Service(39)            Retail / Consumer Packaged Goods(40)            Telecommunications(39)See AllSee LessJob Roles            Artist / Designer(3)            Business Executive(3)            Data Scientist(23)            Dev / IT Operations(38)            Developer / Engineer(60)            Research: Academic(6)            Research: Non-Academic(6)See AllSee LessAPPLYSort by:Alphabetical - A-ZNewestDocumentation CenterCloudera Data Platform (CDP)04/10/23        The integration of NVIDIA RAPIDS into the Cloudera Data Platform (CDP) provides transparent GPU acceleration of data analytics workloads using Apache Spark. This documentation describes the integration and suggested reference architectures for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterFleet Command User Guide06/11/24        NVIDIA Fleet Command brings secure edge AI to enterprises of any size. Transform NVIDIA-certified servers into secure edge appliances and connect them to the cloud in minutes. From the cloud, deploy and manage applications from the NGC Catalog or your NGC Private Registry, update system software over-the-air and manage systems remotely with nothing but a browser and internet connection.    Cloud ServicesEdge ComputingData Center / CloudDocumentation CenterGPU Management and Deployment01/23/23        This documentation should be of interest to cluster admins and support personnel of enterprise GPU deployments. It includes monitoring and management tools and application programming interfaces (APIs), in-field diagnostics and health monitoring, and cluster setup and deployment.    Documentation CenterNVIDIA Megatron-Core03/16/24        Developer documentation for Megatron Core covers API documentation, quickstart guide as well as deep dives into advanced GPU  techniques needed to optimize LLM performance at scale.    Documentation CenternvCOMP01/23/23        nvCOMP is a high performance GPU enabled data compression library. Includes both open-source and non-OS components. The nvCOMP library provides fast lossless data compression and decompression using a GPU. It features generic compression interfaces to enable developers to use high-performance GPU compressors in their applications.    ProductNVIDIA Aerial04/12/23NVIDIA Aerial™ is a suite of accelerated computing platforms, software, and services for designing, simulating, and operating wireless networks. Aerial contains hardened RAN software libraries for telcos, cloud service providers (CSPs), and enterprises building commercial 5G networks. Academic and industry researchers can access Aerial on cloud or on-premises setups for advanced wireless and AI/machine learning (ML) research for 6G.    Edge ComputingTelecommunicationsProductNVIDIA AI Enterprise04/27/23        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications. Easy-to-use microservices provide optimized model performance with enterprise-grade security, support, and stability to ensure a smooth transition from prototype to production for enterprises that run their businesses on AI.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Air06/12/23        A simulation platform that allows users to model data center deployments with full software functionality, creating a digital twin. Transform and streamline network operations by simulating, validating, and automating changes and updates.    Documentation CenterNVIDIA Ansel02/03/23        NVIDIA Ansel is a revolutionary way to capture in-game shots and share the moment. Compose your screenshots from any position, adjust them with post-process filters, capture HDR images in high-fidelity formats, and share them in 360 degrees using your mobile phone, PC, or VR headset.    Documentation CenterNVIDIA API Documentation05/09/24        Your guide to NVIDIA APIs including NIM and CUDA-X microservices.    ProductNVIDIA Base Command Manager10/30/23        NVIDIA Base Command Manager streamlines cluster provisioning, workload management, and infrastructure monitoring. It provides all the tools you need to deploy and manage an AI data center. NVIDIA Base Command Manager Essentials comprises the features of NVIDIA Base Command Manager that are certified for use with NVIDIA AI Enterprise.    Data Center / CloudTechnical OverviewNVIDIA Base Command Platform01/25/23        NVIDIA Base Command Platform is a world-class infrastructure solution for businesses and their data scientists who need a premium AI development experience.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Base OS04/18/23        NVIDIA Base OS implements the stable and fully qualified operating systems for running AI, machine learning, and analytics applications on the DGX platform. It includes system-specific configurations, drivers, and diagnostic and monitoring tools and is available for Ubuntu, Red Hat Enterprise Linux, and Rocky Linux.    Data Center / CloudDocumentation CenterNVIDIA Bright Cluster Manager 03/08/23        NVIDIA Bright Cluster Manager offers fast deployment and end-to-end management for heterogeneous HPC and AI server clusters at the edge, in the data center and in multi/hybrid-cloud environments. It automates provisioning and administration for clusters ranging in size from a single node to hundreds of thousands, supports CPU-based and NVIDIA GPU-accelerated systems, and orchestration with Kubernetes.    HPC / Scientific ComputingEdge ComputingData Center / CloudDocumentation CenterNVIDIA Capture SDK01/23/23        NVIDIA Capture SDK (formerly GRID SDK) enables developers to easily and efficiently capture, and optionally encode, the display content.    Documentation CenterNVIDIA Certification Programs02/06/23        NVIDIA’s program that enables enterprises to confidently deploy hardware solutions that optimally run accelerated workloads—from desktop to data center to edge.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Clara04/27/23        NVIDIA® Clara™ is an open, scalable computing platform that enables developers to build and deploy medical imaging applications into hybrid (embedded, on-premises, or cloud) computing environments to create intelligent instruments and automate healthcare workflows.    Healthcare & Life SciencesComputer Vision / Video AnalyticsProductNVIDIA Cloud Functions        Serverless API to deploy and manage AI workloads on GPUs at planetary scale.    ProductNVIDIA Cloud Native Technologies01/23/23        NVIDIA cloud-native technologies enable developers to build and run GPU-accelerated containers using Docker and Kubernetes.    Cloud ServicesData Center / CloudDocumentation CenterNVIDIA CloudXR SDK02/27/23        CloudXR is NVIDIA's solution for streaming virtual reality (VR), augmented reality (AR), and mixed reality (MR) content from any OpenVR XR application on a remote server--desktop, cloud, data center, or edge.    Documentation CenterNVIDIA Compute Sanitizer04/25/23        Compute Sanitizer is a functional correctness checking suite included in the CUDA toolkit. This suite contains multiple tools that can perform different type of checks. The memcheck tool is capable of precisely detecting and attributing out of bounds and misaligned memory access errors in CUDA applications. The tool can also report hardware exceptions encountered by the GPU. The racecheck tool can report shared memory data access hazards that can cause data races. The initcheck tool can report cases where the GPU performs uninitialized accesses to global memory. The synccheck tool can report cases where the application is attempting invalid usages of synchronization primitives. This document describes the usage of these tools.    ProductNVIDIA CUDA04/03/23        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA cuDNN04/12/23        The NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, attention, matmul, pooling, and normalization.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA cuOpt07/14/23        NVIDIA cuOpt™ is a GPU-accelerated solver that uses heuristics and metaheuristics to solve complex vehicle routing problem variants with a wide range of constraints.    Data ScienceRoboticsProductNVIDIA DALI03/22/23        The NVIDIA Data Loading Library (DALI) is a collection of highly optimized building blocks, and an execution engine, for accelerating the pre-processing of input data for deep learning applications. DALI provides both the performance and the flexibility for accelerating different data pipelines as a single library. This single library can then be easily integrated into different deep learning training and inference applications.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionDocumentation CenterNVIDIA Data Center GPU Drivers01/23/23        NVIDIA Data Center GPU drivers are used in Data Center GPU enterprise deployments for AI, HPC, and accelerated computing workloads. Documentation includes release notes, supported platforms, and cluster setup and deployment.    Documentation CenterNVIDIA Data Center GPU Manager (DCGM)02/03/23        NVIDIA Data Center GPU Manager (DCGM) is a suite of tools for managing and monitoring NVIDIA Data Center GPUs in cluster environments.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionDocumentation CenterNVIDIA Deep Graph Library (DGL)01/23/23        Deep Graph Library (DGL) is a framework-neutral, easy-to-use, and scalable Python library used for implementing and training Graph Neural Networks (GNN). Being framework-neutral, DGL is easily integrated into an existing PyTorch, TensorFlow, or an Apache MXNet workflow.    Documentation CenterNVIDIA Deep Learning Performance07/27/23        GPUs accelerate machine learning operations by performing calculations in parallel. Many operations, especially those representable as matrix multipliers will see good acceleration right out of the box. Even better performance can be achieved by tweaking operation parameters to efficiently use GPU resources. The performance documents present the tips that we think are most widely useful.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA DGX Cloud04/26/24        NVIDIA DGX Cloud is an AI platform for enterprise developers, optimized for the demands of generative AI.    ProductNVIDIA DGX Platform11/03/23        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution. Every aspect of the DGX platform is infused with NVIDIA AI expertise, featuring world-class software, record-breaking NVIDIA-accelerated infrastructure in the cloud or on-premises, and direct access to NVIDIA DGXPerts to speed the ROI of AI for every enterprise.    Hardware / SemiconductorArchitecture / Engineering / ConstructionHPC / Scientific ComputingProductNVIDIA DGX SuperPOD03/17/23        Deployment and management guides for NVIDIA DGX SuperPOD, an AI data center infrastructure platform that enables IT to deliver performance—without compromise—for every user and workload. DGX SuperPOD offers leadership-class accelerated infrastructure and agile, scalable performance for the most challenging AI and high-performance computing (HPC) workloads, with industry-proven results.    Data Center / CloudProductNVIDIA DGX Systems04/24/23        System documentation for the DGX AI supercomputers that deliver world-class performance for large generative AI and mainstream AI workloads.    Data Center / CloudDocumentation CenterNVIDIA DIGITS02/03/23        The NVIDIA Deep Learning GPU Training System (DIGITS) can be used to rapidly train highly accurate deep neural networks (DNNs) for image classification, segmentation, and object-detection tasks. DIGITS simplifies common deep learning tasks such as managing data, designing and training neural networks on multi-GPU systems, monitoring performance in real time with advanced visualizations, and selecting the best-performing model from the results browser for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA DRIVE01/23/23        Learn how to develop for NVIDIA DRIVE®, a scalable computing platform that enables automakers and Tier-1 suppliers to accelerate production of autonomous vehicles.    Documentation CenterNVIDIA EGX01/23/23        The NVIDIA EGX platform delivers the power of accelerated AI computing to the edge with a cloud-native software stack (EGX stack), a range of validated servers and devices, Helm charts, and partners who offer EGX through their products and services.    ProductNVIDIA Enterprise Support and Services06/26/23        NVIDIA’s accelerated computing, visualization, and networking solutions are expediting the speed of business outcomes. NVIDIA’s experts are here for you at every step in this fast-paced journey. With our expansive support tiers, fast implementations, robust professional services, market-leading education, and high caliber technical certifications, we are here to help you achieve success with all parts of NVIDIA’s accelerated computing, visualization, and networking platform.    Documentation CenterNVIDIA FLARE (Federated Learning Active Runtime Environment)02/03/23        FLARE (Federated Learning Active Runtime Environment) is Nvidia’s open source extensible SDK that allows researchers and data scientists to adapt existing ML/DL workflow to a privacy preserving federated paradigm. FLARE makes it possible to build robust, generalizable AI models without sharing data.    ProductNVIDIA Gameworks01/25/23        Documentation for GameWorks-related products and technologies, including libraries (NVAPI, OpenAutomate), code samples (DirectX, OpenGL), and developer tools (Nsight, NVIDIA System Profiler).    GamingContent Creation / RenderingDocumentation CenterNVIDIA GeForce NOW Developer Platform02/03/23        The GeForce NOW Developer Platform is an SDK and toolset empowering integration of, interaction with, and testing on the NVIDIA cloud gaming service.    Documentation CenterNVIDIA GPUDirect Storage06/14/24        NVIDIA GPUDirect Storage (GDS) enables the fastest data path between GPU memory and storage by avoiding copies to and from system memory, thereby increasing storage input/output (IO) bandwidth and decreasing latency and CPU utilization.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA Grace05/30/24        Grace is NVIDIA’s first datacenter CPU. Comprising 72 high-performance Arm v9 cores and featuring the NVIDIA-proprietary Scalable Coherency Fabric (SCF) network-on-chip for incredible core-to-core communication, memory bandwidth and GPU I/O capabilities, Grace provides a high-performance compute foundation in a low-power system-on-chip.    Data Center / CloudDocumentation CenterNVIDIA GVDB Voxels02/03/23        NVIDIA GVDB Voxels is a new framework for simulation, compute and rendering of sparse voxels on the GPU.    Documentation CenterNVIDIA Highlights02/03/23        NVIDIA Highlights enables automatic video capture of key moments, clutch kills, and match-winning plays, ensuring gamers’ best gaming moments are always saved. Once a Highlight is captured, gamers can simply share it directly to Facebook, YouTube, or Weibo right from GeForce Experience’s in-game overlay. Additionally, they can also clip their favorite 15 seconds and share as an animated GIF - all without leaving the game!    ProductNVIDIA Holoscan07/25/23        NVIDIA Holoscan is a hybrid computing platform for medical devices that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core microservices to run surgical video, ultrasound, medical imaging, and other applications anywhere, from embedded to edge to cloud.    Healthcare & Life SciencesDocumentation CenterNVIDIA HPC SDK01/23/23        The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries, and development tools used for developing HPC applications for the NVIDIA platform.    ProductNVIDIA IGX Orin03/23/23        NVIDIA IGX Orin™ is an industrial-grade platform that combines enterprise-level hardware, software, and support. As a single, holistic platform, IGX allows companies to focus on application development and realize the benefits of AI faster.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA IndeX02/03/23        NVIDIA IndeX is a 3D volumetric interactive visualization SDK that allows scientists and researchers to visualize and interact with massive data sets, make real-time modifications, and navigate to the most pertinent parts of the data, all in real-time, to gather better insights faster. IndeX leverages GPU clusters for scalable, real-time, visualization and computing of multi-valued volumetric data together with embedded geometry data.            Load More    OpenFiltersClose filtersFiltersSelected FiltersClear AllProducts            Deep Learning Performance(1)            NVIDIA Air(1)            NVIDIA Virtual GPU (vGPU)(1)Topics            AR / VR(4)            Computer Vision / Video Analytics(7)            Content Creation / Rendering(9)            Conversational AI(2)            Cybersecurity(2)            Data Center / Cloud(30)            Data Science(9)            Edge Computing(11)            Generative AI / LLMs(2)            Networking(3)            Recommenders / Personalization(3)            Robotics(4)            Simulation / Modeling / Design(11)See AllSee LessIndustry Segments            Academia / Higher Education(37)            Aerospace(42)            Agriculture(38)            Architecture / Engineering / Construction(41)            Automotive / Transportation(9)            Cloud Services(41)            Consumer Internet(37)            Energy(42)            Financial Services(40)            Gaming(48)            Hardware / Semiconductor(40)            Healthcare & Life Sciences(22)            HPC / Scientific Computing(48)            Manufacturing(40)            Media & Entertainment(44)            Public Sector(42)            Restaurant / Quick-Service(39)            Retail / Consumer Packaged Goods(40)            Telecommunications(39)See AllSee LessContent Types            Documentation Center(9)            Product(1)            Technical Guide(1)Job Roles            Artist / Designer(3)            Business Executive(3)            Data Scientist(23)            Dev / IT Operations(38)            Developer / Engineer(60)            Research: Academic(6)            Research: Non-Academic(6)See AllSee LessJob Titles            CEO(2)            CTO(5)            Data Analyst(4)            Data Scientist(9)            Developer / Engineer(56)            Film / Video Editor(2)            Graphic Designer / Animator(2)            Industrial Designer / Product Designer(2)            IT Specialist(15)            Solutions Architect(1)            System Administrator(10)See AllSee LessAPPLYProductNVIDIA Virtual GPU (vGPU) Software01/23/23        NVIDIA virtual GPU (vGPU) software is a graphics virtualization platform that extends the power of NVIDIA GPU technology to virtual desktops and apps, offering improved security, productivity, and cost-efficiency.    ProductNVIDIA Clara04/27/23        NVIDIA® Clara™ is an open, scalable computing platform that enables developers to build and deploy medical imaging applications into hybrid (embedded, on-premises, or cloud) computing environments to create intelligent instruments and automate healthcare workflows.    Healthcare & Life SciencesComputer Vision / Video AnalyticsDocumentation CenterNVIDIA Triton Inference Server04/17/23        NVIDIA Triton Inference Server (formerly TensorRT Inference Server) provides a cloud inferencing solution optimized for NVIDIA GPUs. The server provides an inference service via an HTTP or gRPC endpoint, allowing remote clients to request inferencing for any model being managed by the server.    Documentation CenterNVIDIA Maxine02/03/23        NVIDIA Maxine is a GPU-accelerated SDK with state-of-the-art AI features for developers to build virtual collaboration and content creation applications such as video conferencing and live streaming. Maxine’s AI SDKs, such as Video Effects, Audio Effects, and Augmented Reality (AR) are highly optimized and include modular features that can be chained into end-to-end pipelines to deliver the highest performance possible on GPUs, both on PCs and in data centers.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA LaunchPad04/26/23        NVIDIA LaunchPad is a free program that provides users short-term access to a large catalog of hands-on labs. Now enterprises and organizations can immediately tap into the necessary hardware and software stacks to experience end-to-end solution workflows in the areas of AI, data science, 3D design collaboration and simulation, and more.    Edge ComputingData Center / CloudDocumentation CenterNVIDIA GeForce NOW Developer Platform02/03/23        The GeForce NOW Developer Platform is an SDK and toolset empowering integration of, interaction with, and testing on the NVIDIA cloud gaming service.    Documentation CenterNVIDIA VRWorks Graphics02/03/23        VRWorks™ is a comprehensive suite of APIs, libraries, and engines that enable application and headset developers to create amazing virtual reality experiences. VRWorks enables a new level of presence by bringing physically realistic visuals, sound, touch interactions, and simulated environments to virtual reality.    Documentation CenterNVIDIA Data Center GPU Manager (DCGM)02/03/23        NVIDIA Data Center GPU Manager (DCGM) is a suite of tools for managing and monitoring NVIDIA Data Center GPUs in cluster environments.    AerospaceHardware / SemiconductorArchitecture / Engineering / ConstructionProductNVIDIA Optimized Frameworks        Deep learning (DL) frameworks offer building blocks for designing, training, and validating deep neural networks through a high-level programming interface. Widely-used DL frameworks, such as PyTorch, TensorFlow, PyTorch Geometric, DGL, and others, rely on GPU-accelerated libraries, such as cuDNN, NCCL, and DALI to deliver high-performance, multi-GPU-accelerated training.    Documentation CenterNVIDIA GVDB Voxels02/03/23        NVIDIA GVDB Voxels is a new framework for simulation, compute and rendering of sparse voxels on the GPU.    ProductNVIDIA AI Enterprise04/27/23        NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications. Easy-to-use microservices provide optimized model performance with enterprise-grade security, support, and stability to ensure a smooth transition from prototype to production for enterprises that run their businesses on AI.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA MAGNUM IO06/27/23        NVIDIA MAGNUM IO™ software development kit (SDK) enables developers to remove input/output (IO) bottlenecks in AI, high performance computing (HPC), data science, and visualization applications, reducing the end-to-end time of their workflows. Magnum IO covers all aspects of data movement between CPUs, GPUsns, DPUs, and storage subsystems in virtualized, containerized, and bare-metal environments.    ProductNVIDIA CUDA04/03/23        The NVIDIA® CUDA® Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceProductNVIDIA Trusted Computing Solutions07/25/23        Protecting sensitive and proprietary information using strong hardware-based security.    Healthcare & Life SciencesFinancial ServicesData Center / CloudDocumentation CenterCloudera Data Platform (CDP)04/10/23        The integration of NVIDIA RAPIDS into the Cloudera Data Platform (CDP) provides transparent GPU acceleration of data analytics workloads using Apache Spark. This documentation describes the integration and suggested reference architectures for deployment.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Metropolis Microservices for Jetson01/11/24        Metropolis Microservices for Jetson is a platform that simplifies development, deployment and management of Edge AI applications on NVIDIA Jetson. It provides a modular & extensible architecture for developers to distill large complex applications into smaller modular microservice with APIs to integrate into other apps & services.    ProductNVIDIA TAO03/27/23        The NVIDIA TAO Toolkit eliminates the time-consuming process of building and fine-tuning DNNs from scratch for IVA applications.    Public SectorEdge ComputingComputer Vision / Video AnalyticsDocumentation CenterNVIDIA SDK Manager02/03/23        NVIDIA SDK Manager is an all-in-one tool that bundles developer software and provides an end-to-end development environment setup solution for NVIDIA SDKs. Learn about the prerequisite hardware and software to get started with NVIDIA SDK Manager. See the latest features and updates.    Documentation CenterNVIDIA Certification Programs02/06/23        NVIDIA’s program that enables enterprises to confidently deploy hardware solutions that optimally run accelerated workloads—from desktop to data center to edge.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA Ansel02/03/23        NVIDIA Ansel is a revolutionary way to capture in-game shots and share the moment. Compose your screenshots from any position, adjust them with post-process filters, capture HDR images in high-fidelity formats, and share them in 360 degrees using your mobile phone, PC, or VR headset.    ProductNVIDIA Holoscan07/25/23        NVIDIA Holoscan is a hybrid computing platform for medical devices that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core microservices to run surgical video, ultrasound, medical imaging, and other applications anywhere, from embedded to edge to cloud.    Healthcare & Life SciencesProductRAPIDS Accelerator for Apache Spark09/14/23        The RAPIDS Accelerator for Apache Spark leverages GPUs to accelerate processing by combining the power of the RAPIDS cuDF library and the scale of the Spark distributed computing framework. You can run your existing Apache Spark applications on GPUs with no code change by launching Spark with the RAPIDS Accelerator for Apache Spark plugin jar and enabling a single configuration setting.    Data ScienceProductNVIDIA License System02/16/23        NVIDIA® License System is used to serve a pool of floating licenses to NVIDIA licensed products. The NVIDIA License System is configured with licenses obtained from the NVIDIA Licensing Portal.    Data Center / CloudProductNVIDIA NIM05/31/24        Part of NVIDIA AI Enterprise, NVIDIA NIM is a set of easy-to-use microservices for accelerating the deployment of foundation models on any cloud or data center and helps keep your data secure. NIM has production-grade runtimes including on-going security updates. Run your business applications with stable APIs backed by enterprise-grade support.    Documentation CenterNVIDIA FLARE (Federated Learning Active Runtime Environment)02/03/23        FLARE (Federated Learning Active Runtime Environment) is Nvidia’s open source extensible SDK that allows researchers and data scientists to adapt existing ML/DL workflow to a privacy preserving federated paradigm. FLARE makes it possible to build robust, generalizable AI models without sharing data.    ProductNVIDIA Base OS04/18/23        NVIDIA Base OS implements the stable and fully qualified operating systems for running AI, machine learning, and analytics applications on the DGX platform. It includes system-specific configurations, drivers, and diagnostic and monitoring tools and is available for Ubuntu, Red Hat Enterprise Linux, and Rocky Linux.    Data Center / CloudTechnical OverviewNVIDIA Base Command Platform01/25/23        NVIDIA Base Command Platform is a world-class infrastructure solution for businesses and their data scientists who need a premium AI development experience.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA NVTAGS03/22/23        NVIDIA Topology-Aware GPU Selection (NVTAGS) intelligently and automatically assigns GPUs to MPI processes, which reduces overall GPU-to-GPU communication time for Message Passing Interface (MPI) applications.    HPC / Scientific ComputingData Center / CloudDocumentation CenterNVIDIA Rivermax02/03/23        Unique IP-based solution that boosts video and data streaming performance. Rivermax together with NVIDIA GPU accelerated computing technologies unlocks innovation for a wide range of applications in Media and Entertainment (M&E), Broadcast, Healthcare, Smart Cities and more.    Documentation CenterNVIDIA Virtual Reality Capture and Replay (VCR) SDK01/23/23        The NVIDIA Virtual Reality Capture and Replay (VCR) SDK enables developers and users to accurately capture and replay VR sessions for performance testing, scene troubleshooting, and more.    Documentation CenterNVIDIA TensorRT-Cloud06/02/24        The Triton Inference Server provides an optimized cloud and edge inferencing solution.    ProductNVIDIA DGX Systems04/24/23        System documentation for the DGX AI supercomputers that deliver world-class performance for large generative AI and mainstream AI workloads.    Data Center / CloudDocumentation CenterNVIDIA Capture SDK01/23/23        NVIDIA Capture SDK (formerly GRID SDK) enables developers to easily and efficiently capture, and optionally encode, the display content.    Documentation CenternvCOMP01/23/23        nvCOMP is a high performance GPU enabled data compression library. Includes both open-source and non-OS components. The nvCOMP library provides fast lossless data compression and decompression using a GPU. It features generic compression interfaces to enable developers to use high-performance GPU compressors in their applications.    ProductNVIDIA DGX Platform11/03/23        Built from the ground up for enterprise AI, the NVIDIA DGX platform incorporates the best of NVIDIA software, infrastructure, and expertise in a modern, unified AI development and training solution. Every aspect of the DGX platform is infused with NVIDIA AI expertise, featuring world-class software, record-breaking NVIDIA-accelerated infrastructure in the cloud or on-premises, and direct access to NVIDIA DGXPerts to speed the ROI of AI for every enterprise.    Hardware / SemiconductorArchitecture / Engineering / ConstructionHPC / Scientific ComputingProductNVIDIA Aerial04/12/23NVIDIA Aerial™ is a suite of accelerated computing platforms, software, and services for designing, simulating, and operating wireless networks. Aerial contains hardened RAN software libraries for telcos, cloud service providers (CSPs), and enterprises building commercial 5G networks. Academic and industry researchers can access Aerial on cloud or on-premises setups for advanced wireless and AI/machine learning (ML) research for 6G.    Edge ComputingTelecommunicationsProductNVIDIA Cloud Functions        Serverless API to deploy and manage AI workloads on GPUs at planetary scale.    Documentation CenterNVIDIA PyTorch01/23/23        NVIDIA works with Facebook and the community to accelerate PyTorch on NVIDIA GPUs in the main PyTorch branch, as well as, with ready-to-run containers in NGC.    ProductNVIDIA NVSHMEM08/28/23        NVIDIA NVSHMEM is an NVIDIA based “shared memory” library that provides an easy-to-use CPU-side interface to allocate pinned memory that is symmetrically distributed across a cluster of NVIDIA GPUs.    Data Center / CloudProductNVIDIA Modulus04/28/23        NVIDIA Modulus is a deep learning framework that blends the power of physics and partial differential equations (PDEs) with AI to build more robust models for better analysis.    HPC / Scientific ComputingSimulation / Modeling / DesignDocumentation CenterNVIDIA Bright Cluster Manager 03/08/23        NVIDIA Bright Cluster Manager offers fast deployment and end-to-end management for heterogeneous HPC and AI server clusters at the edge, in the data center and in multi/hybrid-cloud environments. It automates provisioning and administration for clusters ranging in size from a single node to hundreds of thousands, supports CPU-based and NVIDIA GPU-accelerated systems, and orchestration with Kubernetes.    HPC / Scientific ComputingEdge ComputingData Center / CloudProductNVIDIA Networking09/05/23        Accelerated Networks for Modern Workloads: One-third of the 30 million data center servers shipped each year are consumed running the software-defined data center stack.    NetworkingProductNVIDIA MONAI04/19/23        The NVIDIA MONAI framework is the open-source foundation being created by Project MONAI. MONAI is a freely available, community-supported, PyTorch-based framework for deep learning in healthcare imaging. It provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.    Healthcare & Life SciencesComputer Vision / Video AnalyticsProductNVIDIA NGX02/14/23        NVIDIA NGX makes it easy to integrate pre-built, AI-based features into applications with the NGX SDK, NGX Core Runtime and NGX Update Module. The NGX infrastructure updates the AI-based features on all clients that use it.    Architecture / Engineering / ConstructionMedia & EntertainmentRestaurant / Quick-ServiceDocumentation CenterNVIDIA DRIVE01/23/23        Learn how to develop for NVIDIA DRIVE®, a scalable computing platform that enables automakers and Tier-1 suppliers to accelerate production of autonomous vehicles.    Documentation CenterNVIDIA RAPIDS 01/23/23        The RAPIDS data science framework is a collection of libraries for running end-to-end data science pipelines completely on the GPU. The interaction is designed to have a familiar look and feel to working in Python, but utilizes optimized NVIDIA CUDA primitives and high-bandwidth GPU memory under the hood.            Load More    Corporate InfoNVIDIA.com HomeAbout NVIDIA\\u200eNVIDIA DeveloperDeveloper HomeBlogResourcesContact UsDeveloper ProgramPrivacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | ContactCopyright © 2024 NVIDIA Corporation\"),\n",
      " Document(metadata={'source': 'https://docs.nvidia.com/gameworkshttps://docs.nvidia.com/cudnn', 'title': 'NVIDIA cuDNN - NVIDIA Docs', 'description': 'The NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, attention, matmul, pooling, and normalization.', 'language': 'en'}, page_content='NVIDIA cuDNN - NVIDIA DocsSubmit SearchNVIDIA DeveloperBlogForumsJoinSubmit SearchNVIDIA DeveloperBlogForumsJoinMenuNVIDIA cuDNNSubmit SearchSubmit SearchNVIDIA Docs Hub\\xa0\\xa0NVIDIA cuDNNThe NVIDIA CUDA® Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, attention, matmul, pooling, and normalization.DocumentationReferencesDownloadsSupportRelease Notes        Current status, software versions, and known issues for NVIDIA cuDNN.                Browse            Installation Guide        This document provides step-by-step instructions on how to install NVIDIA cuDNN.            Browse            Library API        This library is a context-based API that allows for easy multi-threading and (optional) interoperability with CUDA streams. This API lists the data types and API functions per sub-library.                Browse            Developer Guide        This document explains how to use the NVIDIA cuDNN library. While the NVIDIA cuDNN Library API provides per-function API documentation, the Developer Guide gives a more informal end-to-end story about cuDNN’s key capabilities and how to use them.            Browse            Troubleshooting        This document describes the error reporting and API logging utilities for recording the cuDNN API execution and error information. It also helps answer the most commonly asked questions regarding typical use cases.                Browse            Support Matrix        This document lists the supported versions of the OS, NVIDIA CUDA, the CUDA driver, and the hardware for the latest NVIDIA cuDNN release.            Browse            Software License        This document contains specific license terms and conditions for NVIDIA cuDNN. By accepting this agreement, you agree to comply with all the terms and conditions applicable to the specific product(s) included herein.            Browse            Archives        This document provides access to previously released cuDNN documentation versions.            Browse            cuDNN Library        Click on the green buttons that describe your target platform. Only supported platforms will be shown.                Browse            cuDNN Frontend        The cuDNN Frontend (FE) API is a C++ header-only library that wraps the cuDNN C backend API. Both the FE and backend APIs are entry points to the same set of functionality that is commonly referred to as the \"graph API\".                Browse            NVIDIA Developer Program        Join the NVIDIA Developer Program.                Browse            cuDNN Forum        Explore cuDNN forums.                 Browse            cuDNN Developer        Access the latest NVIDIA cuDNN announcements, news, downloads, and training.                 Browse            Technical Blogs        Find more news and tutorials.                 Browse            Corporate InfoNVIDIA.com HomeAbout NVIDIA\\u200eNVIDIA DeveloperDeveloper HomeBlogResourcesContact UsDeveloper ProgramPrivacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | ContactCopyright © 2024 NVIDIA Corporation'),\n",
      " Document(metadata={'source': 'https://docs.nvidia.com/tensorrt', 'title': 'NVIDIA TensorRT - NVIDIA Docs', 'description': 'NVIDIA® TensorRT™ is an SDK for high-performance deep learning inference.  It is designed to work in a complementary fashion with training frameworks such as TensorFlow, PyTorch, and MXNet. It focuses specifically on running an already-trained network quickly and efficiently on NVIDIA hardware. ', 'language': 'en'}, page_content='NVIDIA TensorRT - NVIDIA DocsSubmit SearchNVIDIA DeveloperBlogForumsJoinSubmit SearchNVIDIA DeveloperBlogForumsJoinMenuNVIDIA TensorRTSubmit SearchSubmit SearchNVIDIA Docs Hub\\xa0\\xa0NVIDIA TensorRT        NVIDIA TensorRT    NVIDIA® TensorRT™ is an SDK for high-performance deep learning inference. It is designed to work in a complementary fashion with training frameworks such as TensorFlow, PyTorch, and MXNet. It focuses specifically on running an already-trained network quickly and efficiently on NVIDIA hardware. TensorRT includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for deep learning inference applications. The core of NVIDIA TensorRT is a C++ library that facilitates high-performance inference on NVIDIA GPUs. TensorRT takes a trained network, which consists of a network definition and a set of trained parameters, and produces a highly optimized runtime engine that performs inference for that network. Refer to the following TensorRT product documentation for more information.Documentation CenterNVIDIA TensorRT Documentation        These documents provide information regarding the current NVIDIA TensorRT  release.    January 23, 2023 10:29 PMCorporate InfoNVIDIA.com HomeAbout NVIDIA\\u200eNVIDIA DeveloperDeveloper HomeBlogResourcesContact UsDeveloper ProgramPrivacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | ContactCopyright © 2024 NVIDIA Corporation'),\n",
      " Document(metadata={'source': 'https://rosecrisp.com', 'title': 'Rose Crisp - vCard / Resume / CV', 'description': 'Rose Crisp - vCard / Resume / CV', 'language': 'en'}, page_content=\"Rose Crisp - vCard / Resume / CVRose CrispAboutResumeWorksBlogContactRose CrispDownload CVAbout MeHello! I’m Rose Crisp.Specializing in end-to-end infrastructure to deployment of containerized applications, I am a Cloud Infrastructure Engineer with extensive experience in Kubernetes native application design and optimization.My passion for technology drives me to continuously explore cutting-edge tools and practices, enabling me to design and implement innovative solutions that optimize performance and user experience.With a keen eye for detail and a commitment to excellence, I thrive on turning challenging problems into seamless, efficient solutions.Residence . . . . . North Carolina, USAResumeExperienceFeb, 2020 - PresentSr Service Reliability EngineerRed Hat - Raleigh, NC- Cutting edge proof of concept workload deployment on OpenShift.- Deliver tailored engineering support for enterprise-scale solutions using Kubernetes Operators.- Facilitate training modules for Kubernetes Operator Framework, enhancing partner proficiency.- Develop, build and deploy Kubernetes Operator demos on OpenShift clusters for presentations, and partners.Apr,2019 - Nov,2019Sr Sofware EngineerSAS Institute Inc.- Streamlined project delivery by implementing a CI/CD strategy with Jenkins and GitLab, automating tests, and securing code with BlackDuck and Checkmarx scans.- Enhanced deployment processes using Kubernetes and Docker, managed with Helm for scalability.- Developed infrastructure management scripts utilizing Ansible, Terraform, and Bash, alongside K8s and Helm, to optimize deployment and operations.1994 - 2019Sr Software EngineerSAS Institute Inc.Greenfield methodology, innovative approaches in CI/CD, infra and workflow design prioritize modern, efficient practices.- Ansible, Terraform, Bash, Vault, and OpenStack for efficient and flexible infra configuration, deployment, and maintenance.- Automate CI/CD with Jenkins and GitLab workflow.- Containerized application deployment with Helm charts for scalability and release management.- BlackDuck and Checkmarx security scanning tool to ensure application security by identifying vulnerabilities early in the development cycle./My SkillsCloud InfrastructureAWSTerraformAnsibleKubernetesLanguagesEnglishMandarinSpanishCodingGolang75% PYTHON / PHP85% JavaScript75% HTML / CSS95% KnowledgeAWS AdministrationWebsite hostingLMS(OpenedX) Website development and hostingOpenshiftQuoteChange is the law of life. And those who look only to the past or the present are certain to miss the future., President John F. Kennedy.BlogOperator 101: What is an Operator?In the context of Kubernetes, an Operator is a method of packaging, deploying, and managing a Kubernetes-native application. Operators leverage Custom Controllers and Custom Resource Definitions (CRDs) to extend Kubernetes functionality and define application-specific behavior.A Deep Dive into Level 5 Auto-Pilot Kubernetes OperatorsIn this blog post, we will explore the inner workings of the l5-operator, a Kubernetes operator that manages the lifecycle of Bestie resources. We'll delve into its architecture, key components, and the core logic behind its operations.Streamlining Enterprise Application Deployment with the EAP Operator: A Beginner's GuideIn this article, we'll highlight the benefits of the JBoss Enterprise Application Platform and provide a detailed step-by-step guide on deploying and managing it effortlessly on OpenShift using the EAP Operator.Step by step guide : How to install Open edX Platform on Red Hat Openshift Container Platform.In this blog, we will explore the process of installing Open edX on Red Hat Openshift Container Platform..1Get in TouchAddress . . . . . North Carolina, USAEmail . . . . . rose.crisp.info@gmail.comPhone . . . . . +1 919 360 1189Contact FormSend MessageSearch for:Recent PostsCreativity Is More ThanDesigning the perfectMusic Player DesignA Song And Dance ActBy spite about do of allowRecent CommentsJOHN SMITH on Creativity Is More ThanADAM SMITH on Creativity Is More Thanadmin on Designing the perfectadmin on Designing the perfectJames on Designing the perfectArchivesNovember 2018CategoriesDesignMusicMetaLog inEntries feedComments feedWordPress.org\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from pprint import pprint\n",
    "# List of URLs you want to load (We will crawl the entire site later)\n",
    "urls = [\n",
    "    \"https://docs.nvidia.com\",\n",
    "    \"https://docs.nvidia.com/cuda\",\n",
    "    \"https://docs.nvidia.com/deeplearning\",\n",
    "    \"https://docs.nvidia.com/gameworks\"\n",
    "    \"https://docs.nvidia.com/cudnn\",\n",
    "    \"https://docs.nvidia.com/tensorrt\",\n",
    "    \"https://rosecrisp.com\",\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through each URL and load the page content\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    page = loader.load()\n",
    "    page[0].page_content = page[0].page_content.replace('\\n', '')\n",
    "    data.extend(page)\n",
    "    \n",
    "\n",
    "pprint(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to ChromaDB vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "all_splits = split_docs(data)  # Define the variable \"all_splits\" here\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosecrisp/anaconda3/lib/python3.11/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.5. The latest version is 4.6.5.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_29f4f0f09a484e8a83f7c828cce6c77e_6Rv4zJ1T6RqN in 2.368084ms\",\"time\":\"2024-07-17T10:31:35-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-07-17T10:31:35-04:00\",\"took\":46958}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "\n",
    "\n",
    "# Setup vector database\n",
    "client = weaviate.Client(\n",
    "  embedded_options = EmbeddedOptions()\n",
    ")\n",
    "\n",
    "# Populate vector database\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    client = client,    \n",
    "    documents = all_splits,\n",
    "    embedding = embeddings,\n",
    "    by_text = False\n",
    ")\n",
    "\n",
    "# Define vectorstore as retriever to enable semantic search\n",
    "retriever = vectorstore.as_retriever()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "ollama = Ollama(base_url=\"http://localhost:11434\", model=\"autopilot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question only from the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-07-17T10:31:52-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-07-17T10:31:52-04:00\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ollama\n",
    "    | StrOutputParser()\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am unable to provide information about Rose Crisp as I have not been provided with enough context or details. If you have any specific questions related to her, please provide me with more information so that I can assist you accordingly.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "rag_chain.invoke(\"who is rose crisp\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosecrisp/anaconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce3ea009a434b838f3f1d643778f121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Enter a query:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c860926807d49fdb7073e6718716c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit Query', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ee7baad1b434f8a036b2149876969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Initialize the Ollama model\n",
    "ollama = Ollama(base_url=\"http://localhost:11434\", model=\"autopilot\")\n",
    "\n",
    "# Function to handle the input and display the response\n",
    "def handle_query(sender):\n",
    "    with output:\n",
    "        clear_output(wait=True)  # Ensure the output is cleared only once ready to display new output\n",
    "        print(\"Processing...\")\n",
    "        try:\n",
    "            response = rag_chain.invoke(input_box.value)\n",
    "            display(HTML(f\"<div style='word-wrap: break-word; white-space: pre-wrap;'>Response: {response}</div>\"))\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", str(e))\n",
    "\n",
    "# Create widgets for input and output\n",
    "input_box = widgets.Text(description=\"Enter a query:\")\n",
    "button = widgets.Button(description=\"Submit Query\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Set up the button's event to handle the query\n",
    "button.on_click(handle_query)\n",
    "\n",
    "# Display the widgets\n",
    "display(input_box, button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
